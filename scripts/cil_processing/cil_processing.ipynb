{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing CIL and IFS Datasets\n",
    "\n",
    "## Overview\n",
    "This script processes **Community Infrastructure Levy (CIL)** and **Infrastructure Funding Statement (IFS)** datasets. It performs **data cleaning, filtering, and merging** with reference data before saving the processed datasets into separate CSV files.\n",
    "\n",
    "The purpose of this exercise is to format the manually collected CIL and IFS data for the Data Platform. The first stage of the process of collecting the data involved manually searching local authority sites to obtain information such as start-date, end-date and adoption-dates for the CIL's, as well as URL pathway to the given local authority's website that contains PDFs on their CIL and IFS data. This data was collected in a spreadsheet, which is then processed by this script. \n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Data Cleaning and Filtering\n",
    "The script starts by **removing unnecessary records** based on specific conditions:\n",
    "\n",
    "- Rows where **`document-type`** is `NaN` or `\"OTHER\"` are removed.\n",
    "- Rows where **`document-url`** is `NaN` or `\"OTHER\"` are removed.\n",
    "- Rows where **`adopted-date`** is `\"No CIL\"` are removed.\n",
    "- `\"None\"` and `\"Cannot find a page\"` values are replaced with blank entries.\n",
    "- `\"N/A\"` values in **`adopted-date`** are replaced with blanks.\n",
    "- If **`adopted-date`** contains `\"On hold\"` or `\"In Discussion\"`, the value is copied to **`notes`** and the **`adopted-date`** field is set to blank.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2: Merging with Reference Data\n",
    "The script then **matches local authority codes** from a reference dataset.\n",
    "\n",
    "1. Selects only relevant columns from the reference dataset:  \n",
    "   - `\"local-authority-code\"`  \n",
    "   - `\"official-name\"`\n",
    "\n",
    "2. Extracts a code from both datasets:\n",
    "   - In the main dataset, `\"organisation\"` is copied to a new column **`org_code`**.\n",
    "   - In the reference dataset, `\"official-name\"` is copied to **`org_code`**.\n",
    "\n",
    "3. **Performs a left merge**:\n",
    "   - Matches rows using **`org_code`**.\n",
    "   - Replaces `\"organisation\"` values with their corresponding `\"local-authority-code\"`.\n",
    "\n",
    "4. **Prefixes `\"local-authority:\"`** to all values in `\"organisation\"`.\n",
    "\n",
    "5. Drops unnecessary columns:\n",
    "   - `\"local-authority-code\"`\n",
    "   - `\"official-name\"`\n",
    "   - `\"org_code\"`\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3: Creating and Saving Final Datasets\n",
    "The script **splits** the cleaned data into two separate datasets:\n",
    "\n",
    "1. **CIL Dataset**  \n",
    "   - Filters rows where **`document-type`** is `\"CIL\"`.\n",
    "   - Saves the result as **`cil_dataset.csv`**.\n",
    "\n",
    "2. **IFS Dataset**  \n",
    "   - Filters rows where **`document-type`** is `\"IFS\"`.\n",
    "   - Saves the result as **`ifs_dataset.csv`**.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "✅ **Cleans and filters** the dataset.  \n",
    "✅ **Handles missing values and special cases** in `\"adopted-date\"`.  \n",
    "✅ **Merges local authority reference data** to replace organisation names with official codes.  \n",
    "✅ **Splits data into CIL and IFS datasets** and saves them as CSV files.\n",
    "\n",
    "This script ensures **accurate and structured data processing** for planning-related documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def cil_process(df, df_ref):\n",
    "        \"\"\"\n",
    "    Processes a dataset containing information on Community Infrastructure Levy (CIL) and \n",
    "    Infrastructure Funding Statements (IFS), cleaning the data, handling missing values, \n",
    "    and mapping local authority codes before saving separate datasets for CIL and IFS.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The main dataset containing CIL and IFS documents with associated metadata.\n",
    "    \n",
    "    df_ref : pandas.DataFrame\n",
    "        A reference dataset mapping local authority codes to their official names.\n",
    "\n",
    "    Processing Steps:\n",
    "    ----------------\n",
    "    - Drops rows where 'document-type' or 'document-url' contain NaN or \"OTHER\".\n",
    "    - Removes rows where 'adopted-date' is \"No CIL\".\n",
    "    - Replaces instances of `None` and \"Cannot find a page\" with an empty string.\n",
    "    - Standardises 'adopted-date' by replacing \"N/A\" and `None` with an empty string.\n",
    "    - Moves \"On hold\" or \"In Discussion\" values from 'adopted-date' to 'notes' and sets 'adopted-date' to an empty string.\n",
    "    - Extracts relevant columns from `df_ref` for mapping.\n",
    "    - Extracts organisation codes and maps them using local authority reference data.\n",
    "    - Updates the 'organisation' column with mapped local authority codes, prefixed with \"local-authority:\".\n",
    "    - Drops redundant columns after merging.\n",
    "    - Saves cleaned CIL and IFS datasets separately as CSV files.\n",
    "\n",
    "    Outputs:\n",
    "    -------\n",
    "    - Saves `cil_dataset.csv` containing rows where 'document-type' is \"CIL\".\n",
    "    - Saves `ifs_dataset.csv` containing rows where 'document-type' is \"IFS\".\n",
    "    \"\"\"\n",
    "        \n",
    "    # Define values to drop \n",
    "    doc_type_values_to_drop = [np.nan, 'OTHER']\n",
    "\n",
    "    # Drop rows \n",
    "    df = df[~df[\"document-type\"].isin(doc_type_values_to_drop) & df[\"document-type\"].notna()]\n",
    "    df = df[~df[\"document-url\"].isin(doc_type_values_to_drop) & df[\"document-url\"].notna()]\n",
    "    \n",
    "    # Drop rows where the value in any column is \"No CIL\"\n",
    "    df = df[df[\"adopted-date\"] != \"No CIL\"]\n",
    "\n",
    "    # Strip `None` and \"Cannot find a page\", leaving cells blank\n",
    "    df = df.replace([None, \"Cannot find a page\"], \"\")\n",
    "\n",
    "    # Set `adopted-date` to blank if it contains \"N/A\" or is None\n",
    "    df['adopted-date'] = df['adopted-date'].replace([\"N/A\", None], \"\")\n",
    "\n",
    "    # Copy \"On hold\" or \"In Discussion\" to `notes` and set `adopted-date` to blank\n",
    "    mask = df['adopted-date'].isin(['On hold', 'In Discussion'])\n",
    "    df.loc[mask, 'notes'] = df.loc[mask, 'adopted-date']\n",
    "    df.loc[mask, 'adopted-date'] = \"\"\n",
    "\n",
    "    # Only select relevant columns from df_ref\n",
    "    df_ref = df_ref[[\"local-authority-code\", \"official-name\"]]\n",
    "\n",
    "    # Extract the codes from both df0 and df1\n",
    "    df['org_code'] = df['organisation']\n",
    "    df_ref['org_code'] = df_ref['official-name']\n",
    "\n",
    "    # Perform a left merge and replace organisation with extracted 3-letter codes\n",
    "    df = pd.merge(df, df_ref, on='org_code', how='left')\n",
    "    df['organisation'] = df['local-authority-code']\n",
    "\n",
    "    # Prepend 'local-authority:' to each entry in the 'organisation' column\n",
    "    df['organisation'] = \"local-authority: \" + df['organisation']\n",
    "\n",
    "    # Drop reduntant columns\n",
    "    df = df.drop(columns=['local-authority-code', 'official-name', 'org_code'])\n",
    "\n",
    "    # Create and save CIL dataset\n",
    "    cil_df = df[df[\"document-type\"]==\"CIL\"]\n",
    "    cil_df.to_csv('cil_dataset.csv', index=False)\n",
    "\n",
    "    # Create and save IFS dataset\n",
    "    ifs_df = df[df[\"document-type\"]==\"IFS\"]\n",
    "    ifs_df.to_csv('ifs_dataset.csv', index=False)\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"CIL_schedule_documents - Sheet1.csv\")\n",
    "# Load the organisation reference data\n",
    "df_ref = pd.read_csv(\"C:/Users/DanielGodden/Documents/planning_data/local_plan_data_collection/documents/uk_local_authorities_future.csv\")\n",
    "\n",
    "cil_process(df, df_ref)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
