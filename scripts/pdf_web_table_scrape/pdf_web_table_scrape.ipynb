{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Tables from PDFs and Webpages using Python\n",
    "\n",
    "## Overview\n",
    "This script extracts tables from **PDF files** or **web pages** and saves them as CSV files. It allows users to:\n",
    "- Extract tables from a **local PDF file** using `pdfplumber`\n",
    "- Extract tables from an **HTML page** using `BeautifulSoup`\n",
    "- **Filter tables** based on a keyword found in column names\n",
    "- **Select a specific table** by index (0-based)\n",
    "- Save the extracted **filtered tables** to a specified folder\n",
    "\n",
    "---\n",
    "\n",
    "## Code Breakdown\n",
    "\n",
    "### 1. **Main Function: `extract_table()`**\n",
    "This function orchestrates the extraction process based on the input type.\n",
    "\n",
    "#### **Parameters:**\n",
    "- `input_path_or_url` *(str)*: Either a **local PDF file path** or a **URL** to a webpage.\n",
    "- `table_index` *(int or None)*: If specified, extracts only the table at this 0-based index after filtering.\n",
    "- `key_words` *(str or None)*: If provided, only tables containing this keyword in the column names are returned.\n",
    "- `output_folder` *(str, default=\"output_tables\")*: Folder where extracted tables will be saved as CSV files.\n",
    "\n",
    "#### **Process:**\n",
    "1. **Check if input is a file or a URL**  \n",
    "   - If it's a **PDF file**, call `_extract_from_pdf()`.\n",
    "   - If it's a **webpage**, call `_extract_from_web()`.\n",
    "   - If neither, print an error and return.\n",
    "\n",
    "2. **Normalise column names**  \n",
    "   - Convert all column names to lowercase and remove newline characters (`\\n`) to improve keyword filtering.\n",
    "\n",
    "3. **Filter by keyword**  \n",
    "   - If `key_words` is set, check if any column contains this keyword.\n",
    "\n",
    "4. **Select the specific table index**  \n",
    "   - If `table_index` is specified, extract that particular table.\n",
    "\n",
    "5. **Save the filtered table(s) as CSV**  \n",
    "   - Call `_save_to_csv()` to store the extracted table(s).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Extracting Tables from a PDF: `_extract_from_pdf()`**\n",
    "- Opens the PDF using `pdfplumber`.\n",
    "- Iterates through each page and extracts tables.\n",
    "- Converts extracted tables into Pandas DataFrames.\n",
    "- Returns a list of DataFrames.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Extracting Tables from a Webpage: `_extract_from_web()`**\n",
    "- Uses `requests` to download the webpage content.\n",
    "- Parses the HTML using `BeautifulSoup`.\n",
    "- Searches for `<table>` elements, extracts rows, and stores them in DataFrames.\n",
    "- Returns a list of DataFrames.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Saving Tables as CSV: `_save_to_csv()`**\n",
    "- Creates the output folder if it doesn't exist.\n",
    "- Saves each extracted table as a CSV file with names like `filtered_table_1.csv`, `filtered_table_2.csv`, etc.\n",
    "- Prints confirmation messages for saved files.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Usage\n",
    "\n",
    "### Extracting a Table from a PDF:\n",
    "```python\n",
    "pdf_tables = extract_table(\"sample.pdf\", key_words=\"Purpose of contribution\", table_index=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_table(input_path_or_url, table_index=None, key_words=None, output_folder=\"output_tables\"):\n",
    "    \"\"\"\n",
    "    Extracts tables from a given PDF or webpage and saves them as CSV files.\n",
    "    \n",
    "    Parameters:\n",
    "    input_path_or_url (str): Path to the PDF file or URL.\n",
    "    table_index (int or None): Table index to extract (0-based). If None, return all.\n",
    "    key_words (str or None): If set, extracts only tables containing the keyword.\n",
    "    output_folder (str): Folder name to save the extracted table(s).\n",
    "    \n",
    "    Returns:\n",
    "    list of pandas.DataFrame: Extracted tables as DataFrames.\n",
    "    \"\"\"\n",
    "    extracted_tables = []\n",
    "    \n",
    "    if os.path.isfile(input_path_or_url):  # Input is a file\n",
    "        file_ext = os.path.splitext(input_path_or_url)[-1].lower()\n",
    "        \n",
    "        if file_ext == \".pdf\":\n",
    "            extracted_tables = _extract_from_pdf(input_path_or_url)\n",
    "        else:\n",
    "            print(\"Unsupported file format. Only PDFs are supported.\")\n",
    "            return []\n",
    "    \n",
    "    elif input_path_or_url.startswith(\"http\"):  # Input is a URL\n",
    "        extracted_tables = _extract_from_web(input_path_or_url)\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid input. Provide a valid file path or URL.\")\n",
    "        return []\n",
    "    \n",
    "    if not extracted_tables:\n",
    "        print(\"No tables extracted from the document.\")\n",
    "        return []\n",
    "    \n",
    "    # Normalise column names and print extracted columns for debugging\n",
    "    for i, df in enumerate(extracted_tables):\n",
    "        df.columns = [col.strip().replace(\"\\n\", \" \").lower() if isinstance(col, str) else col for col in df.columns]\n",
    "        print(f\"Table {i+1} Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Filter by keyword if provided\n",
    "    if key_words:\n",
    "        key_words_lower = key_words.lower()\n",
    "        extracted_tables = [df for df in extracted_tables if \n",
    "                            any(key_words_lower in col for col in df.columns)]\n",
    "    \n",
    "    if not extracted_tables:\n",
    "        print(f\"No tables matched the keyword: {key_words}\")\n",
    "        return []\n",
    "    \n",
    "    # Apply table index filtering\n",
    "    if table_index is not None and len(extracted_tables) > table_index:\n",
    "        extracted_tables = [extracted_tables[table_index]]\n",
    "    \n",
    "    # Save only filtered tables\n",
    "    _save_to_csv(extracted_tables, output_folder)\n",
    "    return extracted_tables\n",
    "\n",
    "def _extract_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts tables from a PDF file.\"\"\"\n",
    "    tables = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            extracted = page.extract_table()\n",
    "            if extracted:\n",
    "                df = pd.DataFrame(extracted[1:], columns=extracted[0])\n",
    "                tables.append(df)\n",
    "    return tables\n",
    "\n",
    "def _extract_from_web(url):\n",
    "    \"\"\"Extracts tables from a webpage.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        tables = []\n",
    "        \n",
    "        for table in soup.find_all('table'):\n",
    "            rows = table.find_all('tr')\n",
    "            data = [[cell.get_text(strip=True) for cell in row.find_all(['td', 'th'])] for row in rows]\n",
    "            if data:\n",
    "                df = pd.DataFrame(data[1:], columns=data[0])\n",
    "                tables.append(df)\n",
    "        \n",
    "        return tables\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching webpage: {e}\")\n",
    "        return []\n",
    "\n",
    "def _save_to_csv(tables, output_folder):\n",
    "    \"\"\"Saves extracted tables to CSV files.\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for idx, df in enumerate(tables):\n",
    "        csv_filename = os.path.join(output_folder, f\"filtered_table_{idx+1}.csv\")\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        print(f\"Table saved to {csv_filename}\")\n",
    "\n",
    "# Input\n",
    "input = \"\"\n",
    "\n",
    "\n",
    "# Extract tables from PDF\n",
    "tables = extract_table(input, key_words=\"\", table_index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
