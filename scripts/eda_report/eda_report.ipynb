{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Script for initial analysis and reporting of geospatial dataset**\n",
    "\n",
    "## **Overview**\n",
    "This script automates the processing and reporting of geospatial datasets stored in a directory. The script:\n",
    "1. **Finds geospatial files** (`.shp`, `.gpkg`, `.csv`) in the dataset folder.\n",
    "2. **Analyses each file** to extract metadata (geometry type, record count, CRS, etc.).\n",
    "3. **Generates an interactive map** for each geospatial file.\n",
    "4. **Captures a screenshot** of the map using a headless browser.\n",
    "5. **Creates individual reports** (`.docx`) for each file, which include:\n",
    "   - Metadata about the dataset.\n",
    "   - Folder contents (only in the first report).\n",
    "   - A dataset analysis section.\n",
    "   - A map screenshot.\n",
    "   - A sample of the dataset in GeoJSON format.\n",
    "6. **Merges multiple reports** into a single document while keeping:\n",
    "   - The **main report title** (`{dataset} Analysis Report`) only in the first document.\n",
    "   - The **folder contents** section only once.\n",
    "   - A **level-1 heading** for each shapefile analysis.\n",
    "\n",
    "The purpose of this script is to automate the process of initial analysis of geospatial data. These file types can be difficult to open up and investigate (compared to a csv or excel file), and often need specialist software. This script allows the user to input a dataset of interest, and the script will output a report in the form of a word document. This document will contain information on the contents of the files, the features the data contains, the coordinate system it is using, a plot of a polygon created using the first data entry (provided on a map for better visualisation), and a GeoJSON sample.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step-by-Step Breakdown**\n",
    "\n",
    "### **1. Import Required Libraries**\n",
    "The script imports several Python libraries:\n",
    "- **os**: Manages file paths and sizes.\n",
    "- **geopandas & pandas**: Reads geospatial data from `.shp`, `.gpkg`, and `.csv` files.\n",
    "- **folium**: Generates interactive maps.\n",
    "- **asyncio & pyppeteer**: Captures map screenshots using a headless browser.\n",
    "- **docx**: Creates `.docx` reports.\n",
    "- **docx.shared**: Formats document elements such as images.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Define the `process_dataset` Function**\n",
    "This function:\n",
    "- Takes a dataset name as input.\n",
    "- Finds geospatial files in the dataset's folder.\n",
    "- Iterates through each file, processing and analysing it.\n",
    "- Saves results in individual reports.\n",
    "- Merges reports if multiple files exist.\n",
    "\n",
    "It first defines the folder structure for the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Identify Geospatial Files**\n",
    "The script scans the dataset directory and identifies files with the extensions `.shp`, `.gpkg`, or `.csv`. If no files are found, the script terminates.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Analyse Folder Contents**\n",
    "Before analysing the geospatial files, the script:\n",
    "- Extracts the **size of each file**.\n",
    "- Calculates the **total size of the folder**.\n",
    "- Stores this information for inclusion in the final report.\n",
    "\n",
    "This information is **only added to the first report**.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Process Each Geospatial File**\n",
    "For each geospatial file found, the script:\n",
    "1. **Loads the file into memory**.\n",
    "2. **Extracts metadata** such as:\n",
    "   - Geometry type.\n",
    "   - Record count.\n",
    "   - Feature columns.\n",
    "   - Coordinate reference system (CRS).\n",
    "   - File size.\n",
    "3. **Saves a sample of the dataset** in GeoJSON format (first 50 records).\n",
    "4. **Generates an interactive map** for the dataset.\n",
    "5. **Captures a screenshot** of the map using a headless Chrome browser.\n",
    "6. **Creates a `.docx` report** summarising the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Loading the Geospatial File**\n",
    "- **Shapefiles (`.shp`)** and **GeoPackages (`.gpkg`)** are read using `geopandas`.\n",
    "- **CSV files (`.csv`)** are read using `pandas`.\n",
    "- If an error occurs while loading a file, the script logs the error and moves to the next file.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Extracting Metadata**\n",
    "The script retrieves key details about the dataset:\n",
    "- **Geometry Type**: The type of spatial objects (e.g., `Point`, `Polygon`).\n",
    "- **Record Count**: The number of features in the dataset.\n",
    "- **Feature Columns**: A list of attribute fields.\n",
    "- **CRS (Coordinate Reference System)**: The spatial reference used.\n",
    "- **File Size**: The size of the dataset in bytes.\n",
    "\n",
    "This metadata is included in the report.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Saving a Sample as GeoJSON**\n",
    "The script saves the first 50 records of each dataset in GeoJSON format. This allows a preview of the dataset structure.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Generating an Interactive Map**\n",
    "The script creates an interactive map using `folium` and saves it as an HTML file.\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Capturing a Screenshot of the Map**\n",
    "Since `folium` maps are interactive, they must be converted into images. The script:\n",
    "1. **Opens the saved HTML map** in a headless Chrome browser using `pyppeteer`.\n",
    "2. **Waits for the map to fully load**.\n",
    "3. **Takes a screenshot** and saves it as a PNG file.\n",
    "\n",
    "If an error occurs (e.g., if Chrome is not installed or accessible), the script logs the error and continues.\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Creating an Individual Report**\n",
    "A `.docx` report is generated for each geospatial file. Each report contains:\n",
    "- **Main Title** (`{dataset} Analysis Report`, only in the first report).\n",
    "- **Folder Contents** (only in the first report).\n",
    "- **A Section for the Current File** (`{geospatial_file} Analysis`).\n",
    "- **Metadata** (geometry type, record count, CRS, etc.).\n",
    "- **Dataset Plot** (map screenshot).\n",
    "- **GeoJSON Sample Data** (preview of the dataset in GeoJSON format).\n",
    "\n",
    "If a dataset does not contain an image or GeoJSON sample, placeholders are added.\n",
    "\n",
    "---\n",
    "\n",
    "### **12. Merging Reports**\n",
    "If multiple geospatial files exist, the script:\n",
    "1. **Merges all individual reports into a single document**.\n",
    "2. **Keeps the main report title and folder contents only in the first report**.\n",
    "3. **Adds a level-1 heading before each dataset's analysis** to structure the document properly.\n",
    "\n",
    "The final document is saved in the dataset folder.\n",
    "\n",
    "---\n",
    "\n",
    "## **Final Output**\n",
    "After execution, the script generates:\n",
    "- **Individual Reports** (`.docx` files) for each geospatial dataset.\n",
    "- **A Merged Report** (if multiple files exist), structured as follows:\n",
    "  1. **Title (`{dataset} Analysis Report`)**.\n",
    "  2. **Folder Contents** (only once).\n",
    "  3. **Shapefile Analyses**, each separated by a heading.\n",
    "  4. **Dataset Plots** (screenshots).\n",
    "  5. **GeoJSON Samples**.\n",
    "\n",
    "Each dataset analysis section is properly formatted for clarity.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Features**\n",
    "✅ **Handles multiple geospatial files** and generates structured reports.  \n",
    "✅ **Automatically extracts and saves key dataset information**.  \n",
    "✅ **Creates an interactive map for each dataset**.  \n",
    "✅ **Captures high-quality map screenshots**.  \n",
    "✅ **Formats reports professionally** in `.docx` format.  \n",
    "✅ **Merges reports into a single document with proper headings**.  \n",
    "\n",
    "---\n",
    "\n",
    "## **How to Run the Script**\n",
    "1. **Ensure all dependencies are installed**:\n",
    "   - `pip install geopandas pandas folium pyppeteer python-docx`\n",
    "2. **Set the dataset name**:\n",
    "   - `dataset = \"your_dataset_name\"`\n",
    "3. **Run the function**:\n",
    "   - `await process_dataset(dataset)`\n",
    "\n",
    "The script will automatically process all geospatial files and generate reports.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for geospatial files in: datasets/green_space/files\n",
      "Geospatial files found: ['GB_AccessPoint.shp', 'GB_GreenspaceSite.shp']\n",
      "\n",
      "Processing: GB_AccessPoint.shp (1/2)\n",
      "Sample GeoJSON saved: datasets/green_space/green_space_GB_AccessPoint.shp_sample.geojson\n",
      "Map saved: datasets/green_space/green_space_GB_AccessPoint.shp_plot.png\n",
      "Report saved: datasets/green_space/green_space_GB_AccessPoint.shp_analysis_report.docx\n",
      "\n",
      "Processing: GB_GreenspaceSite.shp (2/2)\n",
      "Sample GeoJSON saved: datasets/green_space/green_space_GB_GreenspaceSite.shp_sample.geojson\n",
      "Map saved: datasets/green_space/green_space_GB_GreenspaceSite.shp_plot.png\n",
      "Report saved: datasets/green_space/green_space_GB_GreenspaceSite.shp_analysis_report.docx\n",
      "\n",
      "Final merged report saved: datasets/green_space/green_space_final_analysis_report.docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import folium\n",
    "import asyncio\n",
    "from pyppeteer import launch\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt\n",
    "\n",
    "async def process_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Processes all shapefiles in a dataset folder by analysing each, generating individual reports,\n",
    "    and then merging them into a single consolidated DOCX report.\n",
    "\n",
    "    Args:\n",
    "        dataset (str): Name of the dataset folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_folder = f\"datasets/{dataset}\"\n",
    "    folder_path = f\"{dataset_folder}/files\"\n",
    "\n",
    "    def find_geospatial_files(folder_path):\n",
    "        \"\"\"Finds geospatial files (.shp, .gpkg, .csv) in the folder.\"\"\"\n",
    "        return [file for file in os.listdir(folder_path) if file.endswith(('.shp', '.gpkg', '.csv'))]\n",
    "\n",
    "    print(f\"Looking for geospatial files in: {folder_path}\")\n",
    "    geospatial_files = find_geospatial_files(folder_path)\n",
    "\n",
    "    if not geospatial_files:\n",
    "        print(\"No geospatial files found.\")\n",
    "        return\n",
    "\n",
    "    print(\"Geospatial files found:\", geospatial_files)\n",
    "\n",
    "    report_files = []\n",
    "\n",
    "    def analyse_folder(folder_path):\n",
    "        \"\"\"Analyses the folder and returns file sizes.\"\"\"\n",
    "        details = {file: f\"Size: {os.path.getsize(os.path.join(folder_path, file))} bytes\"\n",
    "                   for file in os.listdir(folder_path)}\n",
    "        details[\"Total Folder Size\"] = f\"{sum(os.path.getsize(os.path.join(folder_path, file)) for file in os.listdir(folder_path))} bytes\"\n",
    "        return details\n",
    "\n",
    "    folder_description = analyse_folder(folder_path)\n",
    "\n",
    "    for index, geospatial_file in enumerate(geospatial_files):\n",
    "        print(f\"\\nProcessing: {geospatial_file} ({index + 1}/{len(geospatial_files)})\")\n",
    "\n",
    "        geojson_output_file = f\"{dataset_folder}/{dataset}_{geospatial_file}_sample.geojson\"\n",
    "        data_plot_file = f\"{dataset_folder}/{dataset}_{geospatial_file}_plot.png\"\n",
    "        report_output_file = f\"{dataset_folder}/{dataset}_{geospatial_file}_analysis_report.docx\"\n",
    "\n",
    "        def load_geospatial_file(folder_path, file_name):\n",
    "            \"\"\"Loads a geospatial file (.shp, .gpkg, .csv) into a GeoDataFrame.\"\"\"\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                if file_name.endswith(('.shp', '.gpkg')):\n",
    "                    return gpd.read_file(file_path, engine=\"pyogrio\", on_invalid=\"ignore\")\n",
    "                elif file_name.endswith('.csv'):\n",
    "                    return pd.read_csv(file_path)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported file format.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading file: {e}\")\n",
    "                return None\n",
    "\n",
    "        gdf = load_geospatial_file(folder_path, geospatial_file)\n",
    "        if gdf is None:\n",
    "            continue\n",
    "\n",
    "        def analyse_geospatial_file(gdf, geojson_output_file):\n",
    "            \"\"\"Analyses geospatial data and saves a sample as GeoJSON.\"\"\"\n",
    "            try:\n",
    "                gdf.head(50).to_file(geojson_output_file, driver=\"GeoJSON\")\n",
    "                print(f\"Sample GeoJSON saved: {geojson_output_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving GeoJSON: {e}\")\n",
    "                return None\n",
    "\n",
    "            return {\n",
    "                \"geometry_type\": ', '.join(gdf.geom_type.unique()),\n",
    "                \"record_count\": len(gdf),\n",
    "                \"features\": ', '.join(gdf.columns),\n",
    "                \"crs\": str(gdf.crs) if gdf.crs else \"Unknown\",\n",
    "                \"file_size\": os.path.getsize(os.path.join(folder_path, geospatial_file)),\n",
    "                \"geojson_file\": geojson_output_file\n",
    "            }\n",
    "\n",
    "        geospatial_data = analyse_geospatial_file(gdf, geojson_output_file)\n",
    "        if geospatial_data is None:\n",
    "            continue\n",
    "\n",
    "        CHROME_PATH = \"C:/Program Files/Google/Chrome/Application/chrome.exe\"\n",
    "\n",
    "        m = gdf.iloc[:1].explore()\n",
    "        map_html_path = f\"{dataset_folder}/map_{geospatial_file}.html\"\n",
    "        m.save(map_html_path)\n",
    "\n",
    "        async def capture_map():\n",
    "            \"\"\"Captures a screenshot of an interactive map using a headless browser.\"\"\"\n",
    "            try:\n",
    "                browser = await launch(headless=True, executablePath=CHROME_PATH, args=[\"--no-sandbox\"])\n",
    "                page = await browser.newPage()\n",
    "                await page.goto(f\"file://{os.path.abspath(map_html_path)}\")\n",
    "                await asyncio.sleep(3)\n",
    "                await page.screenshot({\"path\": data_plot_file, \"fullPage\": True})\n",
    "                print(f\"Map saved: {data_plot_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error capturing map: {e}\")\n",
    "            finally:\n",
    "                await browser.close()\n",
    "\n",
    "        await capture_map()\n",
    "\n",
    "        def generate_report(folder_data, geospatial_data, output_file, image_file, first_report):\n",
    "            \"\"\"\n",
    "            Generates a report summarising the dataset, including metadata, folder contents, \n",
    "            a map plot, and a GeoJSON sample.\n",
    "\n",
    "            Args:\n",
    "                folder_data (dict): Folder contents.\n",
    "                geospatial_data (dict): Geospatial metadata.\n",
    "                output_file (str): Report file path.\n",
    "                image_file (str): Dataset plot path.\n",
    "                first_report (bool): Whether this is the first report (keeps the main heading & folder contents).\n",
    "            \"\"\"\n",
    "            doc = Document()\n",
    "\n",
    "            if first_report:\n",
    "                doc.add_heading(f\"{dataset} Analysis Report\", 0)\n",
    "                \n",
    "                # Folder contents only in the first report\n",
    "                doc.add_heading('Folder Contents:', level=1)\n",
    "                for file, details in folder_data.items():\n",
    "                    doc.add_paragraph(f\"{file}: {details}\", style='List Bullet')\n",
    "\n",
    "            doc.add_heading(f\"{geospatial_file} Analysis:\", level=1)\n",
    "            doc.add_paragraph(f\"Geometry Type: {geospatial_data['geometry_type']}\", style='List Bullet')\n",
    "            doc.add_paragraph(f\"Number of Records: {geospatial_data['record_count']}\", style='List Bullet')\n",
    "            doc.add_paragraph(f\"Features: {geospatial_data['features']}\", style='List Bullet')\n",
    "            doc.add_paragraph(f\"CRS: {geospatial_data['crs']}\", style='List Bullet')\n",
    "            doc.add_paragraph(f\"File Size: {geospatial_data['file_size']} bytes\", style='List Bullet')\n",
    "\n",
    "            doc.add_heading(\"Dataset Plot\", level=1)\n",
    "            if os.path.exists(image_file):\n",
    "                doc.add_picture(image_file, width=Inches(6))\n",
    "                doc.add_paragraph(f\"Figure: First-row dataset visualisation ({image_file})\")\n",
    "            else:\n",
    "                doc.add_paragraph(\"No image available for visualisation.\")\n",
    "\n",
    "            doc.add_heading(\"GeoJSON Sample Data\", level=1)\n",
    "            if os.path.exists(geospatial_data[\"geojson_file\"]):\n",
    "                with open(geospatial_data[\"geojson_file\"], 'r') as geojson_file:\n",
    "                    doc.add_paragraph(\"Sample GeoJSON content:\")\n",
    "                    doc.add_paragraph(geojson_file.read(2000))\n",
    "            else:\n",
    "                doc.add_paragraph(\"No GeoJSON file available.\")\n",
    "\n",
    "            doc.save(output_file)\n",
    "            print(f\"Report saved: {output_file}\")\n",
    "            return doc\n",
    "\n",
    "        first_report = (index == 0)\n",
    "        generate_report(folder_description, geospatial_data, report_output_file, data_plot_file, first_report)\n",
    "        report_files.append(report_output_file)\n",
    "\n",
    "    if len(report_files) > 1:\n",
    "        final_report_path = f\"{dataset_folder}/{dataset}_final_analysis_report.docx\"\n",
    "        merged_doc = Document(report_files[0])\n",
    "\n",
    "        for report in report_files[1:]:\n",
    "            doc_to_merge = Document(report)\n",
    "            merged_doc.add_page_break()\n",
    "            doc_heading = f\"{geospatial_files[report_files.index(report)]} Analysis:\"\n",
    "            merged_doc.add_heading(doc_heading, level=1)\n",
    "            for element in doc_to_merge.paragraphs:\n",
    "                merged_doc.add_paragraph(element.text)\n",
    "\n",
    "        merged_doc.save(final_report_path)\n",
    "        print(f\"\\nFinal merged report saved: {final_report_path}\")\n",
    "\n",
    "# Example usage:\n",
    "await process_dataset(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
